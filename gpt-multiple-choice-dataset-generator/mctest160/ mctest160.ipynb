{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from config import OPENAI_API_KEY\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sagnikrayc/mctest\n",
    "train_set = load_dataset('sagnikrayc/mctest', 'mc160', split='train')\n",
    "test_set = load_dataset('sagnikrayc/mctest', 'mc160', split='test')\n",
    "validation_set = load_dataset('sagnikrayc/mctest', 'mc160', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'question', 'story', 'properties', 'answer_options', 'answer', 'question_is_multiple'],\n",
      "    num_rows: 280\n",
      "})\n",
      "---story---\n",
      "Tom had to fix some things around the house. He had to fix the door. He had to fix the\\newlinewindow. But before he did anything he had to fix the toilet. Tom called over his best\\newlinefriend Jim to help him. Jim brought with him his friends Molly and Holly. Tom thought that\\newlineJim was going to bring Dolly with him but he didn't. The four of them got to work right\\newlineaway. Fixing the toilet was easy. Fixing the door was also easy but fixing the window was\\newlinevery hard. The window was stuck and could not be opened. They all pushed on the window\\newlinereally hard until finally it opened. Once the window was fixed the four of them made a\\newlinedelicious dinner and talked about all of the good work that they had done. Tom was glad\\newlinethat he had such good friends to help him with his work.\n",
      "---question---\n",
      "What was the hardest thing for Tom and his friends to fix?\n",
      "---answer options---\n",
      "{'A': 'Door', 'B': 'House', 'C': 'Window', 'D': 'Toilet'}\n",
      "---answer---\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "#take a look at the a sample of the dataset\n",
    "print(train_set)\n",
    "# take a look at the first answer, answer options\n",
    "print('---story---')\n",
    "print(train_set[0]['story'])\n",
    "print('---question---')\n",
    "print(train_set[0]['question'])\n",
    "print('---answer options---')\n",
    "print(train_set[0]['answer_options'])\n",
    "print('---answer---')\n",
    "print(train_set[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for prompt\n",
    "PREFIX = '''\n",
    "###### Instructions ######\n",
    "Read the following story and the multiple-choice question, analyze step by step, select the correct option, and give the option letter (e.g., A or B) as your answer.\n",
    "Use the following format to provide your answer and confidence level:\n",
    "Explanation: [insert step-by-step analysis here]\n",
    "Answer and Confidence (0-100): [Your answer, e.g., B], [Your confidence level, e.g., 80]%\n",
    "Note: The confidence level indicates how certain you are about your answer, expressed as a percentage.\n",
    "'''\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_processed_idx(checkpoint_file):\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as file:\n",
    "            last_idx = file.readline()\n",
    "            return int(last_idx.strip()) if last_idx else 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def set_checkpoint_idx(checkpoint_file, idx):\n",
    "    with open(checkpoint_file, 'w') as file:\n",
    "        file.write(str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, csv_file_path, checkpoint_file):\n",
    "    start_idx = get_last_processed_idx(checkpoint_file)\n",
    "    for idx in tqdm(range(start_idx, len(dataset))):\n",
    "        try:\n",
    "            question = dataset['question'][idx]\n",
    "            story = dataset['story'][idx]\n",
    "            options = dataset['answer_options'][idx]\n",
    "            answer = dataset['answer'][idx]\n",
    "\n",
    "            formatted_options = [f\"{key}: {value}\" for key, value in options.items()]\n",
    "            question_input = f\"###### Story ######\\n{story}\\n\\n###### Question ######\\n{question}\\n\" + \"\\n\".join(formatted_options)\n",
    "            prompt = PREFIX + f\"{question_input}\"\n",
    "\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer multiple-choice questions.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            output = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            explanation_match = re.search(r'Explanation: (.*)\\n', output)\n",
    "            explanation = explanation_match.group(1) if explanation_match else \"No explanation found.\"\n",
    "\n",
    "            answer_confidence_match = re.search(r'Answer and Confidence \\((0-100)\\): ([A-D]), (\\d+)%', output)\n",
    "            predicted_answer = answer_confidence_match.group(2).strip() if answer_confidence_match else \"No answer found.\"\n",
    "            confidence_level = int(answer_confidence_match.group(3)) if answer_confidence_match else \"No confidence level found.\"\n",
    "\n",
    "            with open(csv_file_path, 'a+', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if os.path.getsize(csv_file_path) == 0:\n",
    "                    writer.writerow([\"IDX\", \"Question\", \"Story\", \"Options\", \"Predicted Answer\", \"Actual Answer\", \"Confidence Level\", \"Explanation\"])\n",
    "                writer.writerow([idx, question, story, \"\\n\".join(formatted_options), predicted_answer, answer, confidence_level, explanation])\n",
    "\n",
    "            set_checkpoint_idx(checkpoint_file, idx + 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {idx}: {e}\")\n",
    "            # If you want to stop on error use 'break', to continue to the next record use 'continue'\n",
    "            # break\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_output_path = 'mctest160_train_COT.csv'\n",
    "test_csv_output_path = 'mctest160_test_COT.csv'\n",
    "validation_csv_output_path = 'mctest160_validation_COT.csv'\n",
    "train_checkpoint_file = 'mctest160_train_checkpoint.txt'\n",
    "test_checkpoint_file = 'mctest160_test_checkpoint.txt'\n",
    "validation_checkpoint_file = 'mctest160_validation_checkpoint.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [04:59<00:00,  7.30s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_set, train_csv_output_path, train_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [29:19<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(test_set, test_csv_output_path, test_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [15:06<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(validation_set, validation_csv_output_path, validation_checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data to jsonl format\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "def convert_to_jsonl(csv_file_path, jsonl_file_path):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        with jsonlines.open(jsonl_file_path, mode='w') as writer:\n",
    "            for row in csv_reader:\n",
    "                writer.write(row)\n",
    "\n",
    "train_jsonl_output_path = 'train.jsonl'\n",
    "test_jsonl_output_path = 'test.jsonl'\n",
    "validation_jsonl_output_path = 'validation.jsonl'\n",
    "\n",
    "convert_to_jsonl(train_csv_output_path, train_jsonl_output_path)\n",
    "convert_to_jsonl(test_csv_output_path, test_jsonl_output_path)\n",
    "convert_to_jsonl(validation_csv_output_path, validation_jsonl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to import from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e36ff68e0244b8a92aaa61195e00444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c603c0710143d6a932edb87b5516fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb601cc79f24e92a18753b9dcdac7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e7dc124d0742579e2e5a8dbd276a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcf6e779bf4432393e2741936a96311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/394k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35556e41d2cc411c835948e4f9eec4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26ec83093c44fda4f7f9055d4f8e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793e6812e0d745de989b14fc22c5096d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a80d25aa7a64fc2bcfe3fcc57756cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc160_train = load_dataset('BENBENBENb/mc160cot', split='train')\n",
    "mc160_test = load_dataset('BENBENBENb/mc160cot', split='test')\n",
    "mc160_validation = load_dataset('BENBENBENb/mc160cot', split='validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
