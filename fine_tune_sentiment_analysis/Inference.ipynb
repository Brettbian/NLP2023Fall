{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "0pWESO4nVysm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbajxqnzVwFB"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"joyfine/llama2-7b-fine-tuning_QA_Google_20\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"joyfine/llama2-7b-fine-tuning_QA_Google_20\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uq0wcQyAV1Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"truthfulqa\" # truthfulqa, sst2, finance, twitter, google"
      ],
      "metadata": {
        "id": "FHq-kSuHV5Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if test == \"truthfulqa\":\n",
        "    dataset = load_dataset(\"truthful_qa\",\"multiple_choice\")\n",
        "    train_set, test_set = train_test_split(dataset['validation'], test_size=0.2, random_state=42)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    for i in tqdm(range(0,len(test_set['question']),1)): # for i in tqdm(range(0,len(dataset['validation']['question']),1))\n",
        "        # question = dataset['validation']['question'][i]\n",
        "        # data = dataset['validation']['mc1_targets'][i]\n",
        "        question = test_set['question'][i]\n",
        "        data = test_set['mc1_targets'][i]\n",
        "        options = [f\"{chr(65+i)}. {choice}\" for i, choice in enumerate(data['choices'])]\n",
        "        correct_answer = [chr(65+i) for i, label in enumerate(data['labels']) if label == 1]\n",
        "        input = question + '\\n' + '\\n'.join(options)\n",
        "        prompt = f\"Question: [{input}] Please answer the following multiple-choice question and only give me the selected option and provide your confidence level. \\\n",
        "        Note that the confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. Make sure you answer in the following structure: \\n \\\n",
        "        [Answer]: , \\n[Confidence (0-100)]: \\n \\\n",
        "        Note: The confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. \\\n",
        "        For instance, if your confidence level is 80%, it means you are 80% certain that your answer is correct and there is a 20% chance that it may be incorrect. \"\n",
        "        prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "\n",
        "        '''\n",
        "        input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
        "        output = tokenizer.decode(output[0])\n",
        "        answer_match = re.search(r'\\[Answer\\]: (\\w)', output)\n",
        "        confidence_match = re.search(r'\\[Confidence \\(0\\-100\\)\\]: (\\d+)', output)\n",
        "        answer = answer_match.group(1) if answer_match else output\n",
        "        confidence_level = int(confidence_match.group(1)) if confidence_match else output\n",
        "        # print(answer, confidence_level)\n",
        "        with open('/content/drive/MyDrive/1011_truthfulQA/truthfulQA_256.csv', 'a+', newline='', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "\n",
        "            # Writing headers\n",
        "            if os.path.getsize('/content/drive/MyDrive/1011_truthfulQA/truthfulQA_256.csv') == 0:\n",
        "                writer.writerow([\"Question\", \"Options\", \"Predicted Answer\", \"Correct Answer\", \"Confidence Level\", \"output\"])\n",
        "\n",
        "            # Writing data\n",
        "            writer.writerow([question, \"\\n\".join(options), answer, correct_answer[0], confidence_level, output])\n",
        "\n",
        "elif test == \"sst2\":\n",
        "    dataset = load_dataset(\"sst2\")\n",
        "    test_set = dataset['validation']\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    start = 0\n",
        "    max = len(test_set['sentence'])\n",
        "    prefix = '''Read this sentence, select the correct sentiment for it and give the option letter: A: positive and B: negative \\\n",
        "    Use the following format to provide your answer and confidence level: \\n\n",
        "    Answer and Confidence (0-100): [Your answer, please only include the capital letter], \\\n",
        "    [Your confidence level, please only include the numerical number]% \\n\n",
        "    Note: The confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. \\\n",
        "    For instance, if your confidence level is 80%, it means you are 80% certain that your answer is correct and there is a 20% chance that it may be incorrect.'''\n",
        "\n",
        "    for sentence,label in tqdm(zip(test_set['sentence'][start:max],test_set['label'][start:max])):\n",
        "        correct_answer = 'A' if label == 1 else 'B'\n",
        "        input = sentence + '\\n'\n",
        "        prompt = prefix + f\"Sentence: [{input}]\"\n",
        "        prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:'''\n",
        "\n",
        "        input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=5, max_new_tokens=512)\n",
        "        output = tokenizer.decode(output[0])\n",
        "        answer_confidence = re.search(r'Answer and Confidence(?: \\(0-100\\))?: (.+), (\\d{1,3})%', output)\n",
        "        answer = answer_confidence.group(1).strip() if answer_confidence else output\n",
        "        confidence_level = int(answer_confidence.group(2)) if answer_confidence else output\n",
        "        options = ['A. Positive', 'B. Negative']\n",
        "        with open('/content/drive/MyDrive/output_1011_parameter/SST2_16_again.csv', 'a+', newline='', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            if os.path.getsize('/content/drive/MyDrive/output_1011_parameter/SST2_16_again.csv') == 0:\n",
        "                writer.writerow([\"Question\", \"Options\", \"Predicted Answer\", \"Correct Answer\", \"Confidence Level\", \"output\"])\n",
        "            writer.writerow([sentence, \"\\n\".join(options), answer, correct_answer[0], confidence_level, output])\n",
        "\n",
        "elif test == \"finance\":\n",
        "    random_seed = 42\n",
        "    dataset = load_dataset(\"financial_phrasebank\", 'sentences_allagree')\n",
        "    df = pd.DataFrame.from_dict(dataset[\"train\"])\n",
        "    train = df.sample(n=754, random_state=random_seed)\n",
        "    df_remaining = df.drop(train.index)\n",
        "    test_set = df_remaining.sample(frac=0.2, random_state=random_seed)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    start = 0\n",
        "    # max = len(test_set['sentence'])\n",
        "    max = 90\n",
        "    prefix = '''Read this sentence, select the correct sentiment for it and give the option letter: A: positive, B: negative and C: neutral. \\\n",
        "    Use the following format to provide your answer and confidence level. \\n\n",
        "    Answer and Confidence (0-100): [Your answer, please only include the capital letter], \\\n",
        "    [Your confidence level, please only include the numerical number]% \\n\n",
        "    Note: The confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. \\\n",
        "    For instance, if your confidence level is 80%, it means you are 80% certain that your answer is correct and there is a 20% chance that it may be incorrect.'''\n",
        "\n",
        "    for sentence,label in tqdm(zip(test_set['sentence'][start:max],test_set['label'][start:max])):\n",
        "        correct_answer = 'A' if label == 2 else ('B' if label == 0 else 'C')\n",
        "        input = sentence + '\\n'\n",
        "        prompt = prefix + f\"Sentence: [{input}]\"\n",
        "        prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:'''\n",
        "\n",
        "        input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=5, max_new_tokens=512)\n",
        "        output = tokenizer.decode(output[0])\n",
        "        answer_confidence = re.search(r'Answer and Confidence(?: \\(0-100\\))?: (.+), (\\d{1,3})%', output)\n",
        "        answer = answer_confidence.group(1).strip() if answer_confidence else output\n",
        "        confidence_level = int(answer_confidence.group(2)) if answer_confidence else output\n",
        "        options = ['A. Positive', 'B. Negative', 'C. Neutral']\n",
        "        with open('/content/drive/MyDrive/output_1011_parameter/Finance_64.csv', 'a+', newline='', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            if os.path.getsize('/content/drive/MyDrive/output_1011_parameter/Finance_64.csv') == 0:\n",
        "                writer.writerow([\"Question\", \"Options\", \"Predicted Answer\", \"Correct Answer\", \"Confidence Level\", \"output\"])\n",
        "            writer.writerow([sentence, \"\\n\".join(options), answer, correct_answer[0], confidence_level, output])\n",
        "\n",
        "elif test == \"twitter\":\n",
        "    dataset = load_dataset(\"carblacac/twitter-sentiment-analysis\")\n",
        "    random_seed = 42\n",
        "    df = pd.DataFrame.from_dict(dataset[\"test\"])\n",
        "    test_set = df.sample(n=319, random_state=random_seed)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    start = 0\n",
        "    max = len(test_set['text'])\n",
        "    prefix = '''Read this sentence, select the correct sentiment for it and give the option letter: A: positive and B: negative \\\n",
        "    Use the following format to provide your answer and confidence level: \\n\n",
        "    Answer and Confidence (0-100): [Your answer, please only include the capital letter], \\\n",
        "    [Your confidence level, please only include the numerical number]% \\n\n",
        "    Note: The confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. \\\n",
        "    For instance, if your confidence level is 80%, it means you are 80% certain that your answer is correct and there is a 20% chance that it may be incorrect.'''\n",
        "\n",
        "    for sentence,label in tqdm(zip(test_set['text'][start:max],test_set['feeling'][start:max])):\n",
        "        correct_answer = 'A' if label == 1 else 'B'\n",
        "        input = sentence + '\\n'\n",
        "        prompt = prefix + f\"Sentence: [{input}]\"\n",
        "        prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:'''\n",
        "\n",
        "        input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=5, max_new_tokens=512)\n",
        "        output = tokenizer.decode(output[0])\n",
        "        answer_confidence = re.search(r'Answer and Confidence(?: \\(0-100\\))?: (.+), (\\d{1,3})%', output)\n",
        "        answer = answer_confidence.group(1).strip() if answer_confidence else output\n",
        "        confidence_level = int(answer_confidence.group(2)) if answer_confidence else output\n",
        "        options = ['A. Positive', 'B. Negative']\n",
        "        with open('/content/drive/MyDrive/output_1011_parameter/Twitter_64.csv', 'a+', newline='', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            if os.path.getsize('/content/drive/MyDrive/output_1011_parameter/Twitter_64.csv') == 0:\n",
        "                writer.writerow([\"Question\", \"Options\", \"Predicted Answer\", \"Correct Answer\", \"Confidence Level\", \"output\"])\n",
        "            writer.writerow([sentence, \"\\n\".join(options), answer, correct_answer[0], confidence_level, output])\n",
        "elif test == \"google\":\n",
        "    random_seed = 42\n",
        "    df = pd.read_csv('/content/drive/MyDrive/google_play_comments.csv', encoding='latin-1')\n",
        "    train = df.sample(n=650, random_state=random_seed)\n",
        "    df_remaining = df.drop(train.index)\n",
        "    test_set = df_remaining.sample(n=306, random_state=random_seed)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    start = 0\n",
        "    max = len(test_set['comment'])\n",
        "    prefix = '''Read this sentence, select the correct sentiment for it and give the option letter: A: positive and B: negative \\\n",
        "    Use the following format to provide your answer and confidence level: \\n\n",
        "    Answer and Confidence (0-100): [Your answer, please only include the capital letter], \\\n",
        "    [Your confidence level, please only include the numerical number]% \\n\n",
        "    Note: The confidence level indicates the degree of certainty you have about your answer and is represented as a percentage. \\\n",
        "    For instance, if your confidence level is 80%, it means you are 80% certain that your answer is correct and there is a 20% chance that it may be incorrect.'''\n",
        "\n",
        "    for sentence,label in tqdm(zip(test_set['comment'][start:max],test_set['label'][start:max])):\n",
        "        correct_answer = 'A' if label == 1 else 'B'\n",
        "        input = sentence + '\\n'\n",
        "        prompt = prefix + f\"Sentence: [{input}]\"\n",
        "        prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:'''\n",
        "\n",
        "        input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=5, max_new_tokens=512)\n",
        "        output = tokenizer.decode(output[0])\n",
        "        answer_confidence = re.search(r'Answer and Confidence(?: \\(0-100\\))?: (.+), (\\d{1,3})%', output)\n",
        "        answer = answer_confidence.group(1).strip() if answer_confidence else output\n",
        "        confidence_level = int(answer_confidence.group(2)) if answer_confidence else output\n",
        "        options = ['A. Positive', 'B. Negative']\n",
        "        with open('/content/drive/MyDrive/output_1011_parameter/GooglePlay_512.csv', 'a+', newline='', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            if os.path.getsize('/content/drive/MyDrive/output_1011_parameter/GooglePlay_512.csv') == 0:\n",
        "                writer.writerow([\"Question\", \"Options\", \"Predicted Answer\", \"Correct Answer\", \"Confidence Level\", \"output\"])\n",
        "            writer.writerow([sentence, \"\\n\".join(options), answer, correct_answer[0], confidence_level, output])"
      ],
      "metadata": {
        "id": "EI1ZjQz4V5bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}