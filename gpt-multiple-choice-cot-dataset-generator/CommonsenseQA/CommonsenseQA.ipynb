{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from config import OPENAI_API_KEY\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, with 600 examples\n",
    "train = load_dataset(\"commonsense_qa\", split=\"train\")\n",
    "val = load_dataset(\"commonsense_qa\", split=\"validation\")\n",
    "test = load_dataset(\"commonsense_qa\", split=\"test\")\n",
    "\n",
    "# sample 600 examples from the training set\n",
    "train = train.shuffle(seed=42).select(range(600))\n",
    "val = val.shuffle(seed=42).select(range(200))\n",
    "test = test.shuffle(seed=42).select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "    num_rows: 600\n",
      "})\n",
      "{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['table', 'post office', \"neighbor's house\", 'railway station', 'fridge']}\n"
     ]
    }
   ],
   "source": [
    "#take a look at the a sample of the dataset\n",
    "print(train)\n",
    "print(train[0]['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for prompt\n",
    "PREFIX = '''\n",
    "###### Instructions ######\n",
    "Read the following multiple-choice question, analyze step by step, select the correct option, and give the option letter (e.g., A or B) as your answer.\n",
    "Use the following format to provide your answer and confidence level:\n",
    "Explanation: [insert step-by-step analysis here]\n",
    "Answer and Confidence (0-100): [Your answer, e.g., B], [Your confidence level, e.g., 80]%\n",
    "Note: The confidence level indicates how certain you are about your answer, expressed as a percentage.\n",
    "'''\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the last processed index from a checkpoint file.\n",
    "# If the checkpoint file exists and contains a number, it returns that number as an integer.\n",
    "# If the checkpoint file is empty or does not exist, it returns 0.\n",
    "def get_last_processed_idx(checkpoint_file):\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as file:\n",
    "            last_idx = file.readline()\n",
    "            return int(last_idx.strip()) if last_idx else 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# This function writes the given index to a checkpoint file.\n",
    "# This is used to save the current progress, so if the process is interrupted,\n",
    "# it can resume from the last saved index instead of starting over.\n",
    "def set_checkpoint_idx(checkpoint_file, idx):\n",
    "    with open(checkpoint_file, 'w') as file:\n",
    "        file.write(str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes a dataset of multiple-choice questions by iterating from the last processed index.\n",
    "# It formats each question and its associated options, sends them to a GPT model for completion,\n",
    "# then records the model's predicted answer, confidence level, and explanation in a CSV file.\n",
    "# It updates the checkpoint after each entry is processed to ensure resumability of the task.\n",
    "def process_dataset(dataset, csv_file_path, checkpoint_file):\n",
    "    '''\n",
    "    dataset: the dataset to process\n",
    "    csv_file_path: the path to the CSV file to write the results to\n",
    "    checkpoint_file: the path to the checkpoint file to save the last processed index to\n",
    "    '''\n",
    "    start_idx = get_last_processed_idx(checkpoint_file)\n",
    "    print(f\"Starting from index {start_idx}\")\n",
    "    for idx in tqdm(range(start_idx, len(dataset))):\n",
    "        try:\n",
    "            # rows are in form of ['id', 'question', 'question_concept', 'choices', 'answerKey']\n",
    "            # choices are in form of {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['table', 'post office', \"neighbor's house\", 'railway station', 'fridge']}\n",
    "            question = dataset['question'][idx]\n",
    "            answerKey = dataset['answerKey'][idx]\n",
    "            question_concept = dataset['question_concept'][idx]\n",
    "            choices = dataset['choices'][idx]\n",
    "\n",
    "            # {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['table', 'post office', \"neighbor's house\", 'railway station', 'fridge']}\n",
    "            # formatted_options = [f\"{chr(ord('A') + i)}. {option}\" for i, option in enumerate(choices)]\n",
    "            formatted_options = [f\"{choices['label'][i]}. {choices['text'][i]}\" for i in range(len(choices['label']))]\n",
    "            question_input = f\"###### Question ######\\n{question}\\n\" + \"\\n\".join(formatted_options)\n",
    "            prompt = PREFIX + f\"{question_input}\"\n",
    "\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer multiple-choice questions.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            output = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            explanation_match = re.search(r'Explanation: (.*)\\n', output)\n",
    "            explanation = explanation_match.group(1) if explanation_match else \"No explanation found.\"\n",
    "\n",
    "            answer_confidence_match = re.search(r'Answer and Confidence \\((0-100)\\): ([A-D]), (\\d+)%', output)\n",
    "            predicted_answer = answer_confidence_match.group(2).strip() if answer_confidence_match else \"No answer found.\"\n",
    "            confidence_level = int(answer_confidence_match.group(3)) if answer_confidence_match else \"No confidence level found.\"\n",
    "\n",
    "            with open(csv_file_path, 'a+', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if os.path.getsize(csv_file_path) == 0:\n",
    "                    writer.writerow([\"id\", \"question\", \"question_concept\", \"choices\", \"predicted_answer\", \"answerKey\", \"confidence_level\", \"explanation\"])\n",
    "                writer.writerow([idx, question, question_concept, choices, predicted_answer, answerKey, confidence_level, explanation])\n",
    "\n",
    "            set_checkpoint_idx(checkpoint_file, idx + 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {idx}: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_output_path = 'train.csv'\n",
    "validation_csv_output_path = 'validation.csv'\n",
    "train_checkpoint_file = 'train_checkpoint.txt'\n",
    "validation_checkpoint_file = 'validation_checkpoint.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from index 593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:47<00:00,  6.78s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train, train_csv_output_path, train_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from index 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [28:52<00:00,  9.42s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(val, validation_csv_output_path, validation_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we convert a CSV file to a JSONL (JSON Lines) to ho on platforms like Hugging Face.\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "# convert csv to jsonl\n",
    "def convert_to_jsonl(csv_file_path, jsonl_file_path):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        with jsonlines.open(jsonl_file_path, mode='w') as writer:\n",
    "            for row in csv_reader:\n",
    "                writer.write(row)\n",
    "\n",
    "# save train and validation set to jsonl\n",
    "train_jsonl_output_path = 'train.jsonl'\n",
    "validation_jsonl_output_path = 'validation.jsonl'\n",
    "\n",
    "convert_to_jsonl(train_csv_output_path, train_jsonl_output_path)\n",
    "convert_to_jsonl(validation_csv_output_path, validation_jsonl_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test set to jsonl\n",
    "# ensure it has same schema as train and validation set, with 'predicted_answer', 'confidence_level', 'explanation' left to be None\n",
    "test_jsonl_output_path = 'test.jsonl'\n",
    "with jsonlines.open(test_jsonl_output_path, mode='w') as writer:\n",
    "    for idx in range(len(test)):\n",
    "        try:\n",
    "            # rows are in form of 'example_id', 'article', 'answer', 'question', 'options'\n",
    "            question = test['question'][idx]\n",
    "            answerKey = test['answerKey'][idx]\n",
    "            choices = test['choices'][idx]\n",
    "            concept = test['question_concept'][idx]\n",
    "            \n",
    "            formatted_options = [f\"{choices['label'][i]}. {choices['text'][i]}\" for i in range(len(choices['label']))]\n",
    "\n",
    "            writer.write({\n",
    "                'id': str(idx),\n",
    "                \"question\": question,\n",
    "                \"question_concept\": concept,\n",
    "                \"choices\": \"\\n\".join(formatted_options),\n",
    "                \"predicted_answer\": None,\n",
    "                \"answerKey\": answerKey,\n",
    "                \"confidence_level\": None,\n",
    "                \"explanation\": None\n",
    "            })\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"str\",\n",
      "  \"question\": \"str\",\n",
      "  \"question_concept\": \"str\",\n",
      "  \"choices\": \"str\",\n",
      "  \"predicted_answer\": \"str\",\n",
      "  \"answerKey\": \"str\",\n",
      "  \"confidence_level\": \"str\",\n",
      "  \"explanation\": \"str\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"str\",\n",
      "  \"question\": \"str\",\n",
      "  \"question_concept\": \"str\",\n",
      "  \"choices\": \"str\",\n",
      "  \"predicted_answer\": \"NoneType\",\n",
      "  \"answerKey\": \"str\",\n",
      "  \"confidence_level\": \"NoneType\",\n",
      "  \"explanation\": \"NoneType\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print shema of train, validation, and test set for jsonl\n",
    "import json\n",
    "\n",
    "def print_jsonl_schema(jsonl_file_path):\n",
    "    with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
    "        first_line = file.readline()\n",
    "        json_object = json.loads(first_line)\n",
    "\n",
    "        schema = {key: type(value).__name__ for key, value in json_object.items()}\n",
    "        print(json.dumps(schema, indent=2))\n",
    "\n",
    "print_jsonl_schema(train_jsonl_output_path)\n",
    "# print_jsonl_schema(validation_jsonl_output_path)\n",
    "print_jsonl_schema(test_jsonl_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b36dd25e2148feb1d693cce7d022fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3294c33dec41b281473b351cd21c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e22d969d97944e489fbf8637a7ab682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/514k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fde37fb6aa14d16924ee7c5ab20e452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/164k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc697fc062e40929cf125dedae786d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/61.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033fc72bf70f4ddc9b3b45a2f3657dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac009e407e6d4a16921961954804669c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9593ed80c9da433fa07baabac044cbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe877281f914ed08e77e0bce08ed335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768b3789558444d7acf024dd0daeb64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533b181c0eb947219ed3838387dd5a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31932855303d4680b5356184d4ab9af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3476bb2c0ed844dba85c8d214ab72ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0096a490bfc14010a8d6e3697a686120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946073de2ff741e59c35dcee2d2f83c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317f6ff58c044f98e2d8f63b6989414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f64e13e4f034ec3b3c69b22ca337af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1a95ff2d9f42f088d23f0b8c1b2fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ffb8b0cd9b43d9bcd6f49b563284a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to load the uploaded dataset from huggingface BENBENBENb/CommonsenseQA1000COT\n",
    "from datasets import load_dataset\n",
    "train_huggingface_dataset = load_dataset('BENBENBENb/CommonsenseQA1000COT', 'train')\n",
    "validation_huggingface_dataset = load_dataset('BENBENBENb/CommonsenseQA1000COT', 'validation')\n",
    "test_huggingface_dataset = load_dataset('BENBENBENb/CommonsenseQA1000COT', 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
