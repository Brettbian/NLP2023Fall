{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from config import OPENAI_API_KEY\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sagnikrayc/mctest\n",
    "train_set = load_dataset('sagnikrayc/mctest', 'mc160', split='train')\n",
    "test_set = load_dataset('sagnikrayc/mctest', 'mc160', split='test')\n",
    "validation_set = load_dataset('sagnikrayc/mctest', 'mc160', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'question', 'story', 'properties', 'answer_options', 'answer', 'question_is_multiple'],\n",
      "    num_rows: 280\n",
      "})\n",
      "---answer options---\n",
      "{'A': 'Door', 'B': 'House', 'C': 'Window', 'D': 'Toilet'}\n"
     ]
    }
   ],
   "source": [
    "#take a look at the a sample of the dataset\n",
    "print(train_set)\n",
    "print('---answer options---')\n",
    "print(train_set[0]['answer_options'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for prompt\n",
    "PREFIX = '''\n",
    "###### Instructions ######\n",
    "Read the following story and the multiple-choice question, analyze step by step, select the correct option, and give the option letter (e.g., A or B) as your answer.\n",
    "Use the following format to provide your answer and confidence level:\n",
    "Explanation: [insert step-by-step analysis here]\n",
    "Answer and Confidence (0-100): [Your answer, e.g., B], [Your confidence level, e.g., 80]%\n",
    "Note: The confidence level indicates how certain you are about your answer, expressed as a percentage.\n",
    "'''\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the last processed index from a checkpoint file.\n",
    "# If the checkpoint file exists and contains a number, it returns that number as an integer.\n",
    "# If the checkpoint file is empty or does not exist, it returns 0.\n",
    "def get_last_processed_idx(checkpoint_file):\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as file:\n",
    "            last_idx = file.readline()\n",
    "            return int(last_idx.strip()) if last_idx else 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# This function writes the given index to a checkpoint file.\n",
    "# This is used to save the current progress, so if the process is interrupted,\n",
    "# it can resume from the last saved index instead of starting over.\n",
    "def set_checkpoint_idx(checkpoint_file, idx):\n",
    "    with open(checkpoint_file, 'w') as file:\n",
    "        file.write(str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes a dataset of multiple-choice questions by iterating from the last processed index.\n",
    "# It formats each question and its associated options, sends them to a GPT model for completion,\n",
    "# then records the model's predicted answer, confidence level, and explanation in a CSV file.\n",
    "# It updates the checkpoint after each entry is processed to ensure resumability of the task.\n",
    "def process_dataset(dataset, csv_file_path, checkpoint_file):\n",
    "    '''\n",
    "    dataset: the dataset to process\n",
    "    csv_file_path: the path to the CSV file to write the results to\n",
    "    checkpoint_file: the path to the checkpoint file to save the last processed index to\n",
    "    '''\n",
    "    start_idx = get_last_processed_idx(checkpoint_file)\n",
    "    print(f\"Starting from index {start_idx}\")\n",
    "    for idx in tqdm(range(start_idx, len(dataset))):\n",
    "        try:\n",
    "            question = dataset['question'][idx]\n",
    "            story = dataset['story'][idx]\n",
    "            options = dataset['answer_options'][idx]\n",
    "            answer = dataset['answer'][idx]\n",
    "\n",
    "            formatted_options = [f\"{key}: {value}\" for key, value in options.items()]\n",
    "            question_input = f\"###### Story ######\\n{story}\\n\\n###### Question ######\\n{question}\\n\" + \"\\n\".join(formatted_options)\n",
    "            prompt = PREFIX + f\"{question_input}\"\n",
    "\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer multiple-choice questions.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            output = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            explanation_match = re.search(r'Explanation: (.*)\\n', output)\n",
    "            explanation = explanation_match.group(1) if explanation_match else \"No explanation found.\"\n",
    "\n",
    "            answer_confidence_match = re.search(r'Answer and Confidence \\((0-100)\\): ([A-D]), (\\d+)%', output)\n",
    "            predicted_answer = answer_confidence_match.group(2).strip() if answer_confidence_match else \"No answer found.\"\n",
    "            confidence_level = int(answer_confidence_match.group(3)) if answer_confidence_match else \"No confidence level found.\"\n",
    "\n",
    "            with open(csv_file_path, 'a+', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                if os.path.getsize(csv_file_path) == 0:\n",
    "                    writer.writerow([\"IDX\", \"Question\", \"Story\", \"Options\", \"Predicted Answer\", \"Actual Answer\", \"Confidence Level\", \"Explanation\"])\n",
    "                writer.writerow([idx, question, story, \"\\n\".join(formatted_options), predicted_answer, answer, confidence_level, explanation])\n",
    "\n",
    "            set_checkpoint_idx(checkpoint_file, idx + 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at index {idx}: {e}\")\n",
    "            # If you want to stop on error use 'break', to continue to the next record use 'continue'\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_output_path = 'train.csv'\n",
    "test_csv_output_path = 'test.csv'\n",
    "validation_csv_output_path = 'validation.csv'\n",
    "train_checkpoint_file = 'train_checkpoint.txt'\n",
    "test_checkpoint_file = 'test_checkpoint.txt'\n",
    "validation_checkpoint_file = 'validation_checkpoint.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [04:59<00:00,  7.30s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_set, train_csv_output_path, train_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [29:19<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(test_set, test_csv_output_path, test_checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [15:06<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(validation_set, validation_csv_output_path, validation_checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we convert a CSV file to a JSONL (JSON Lines) to ho on platforms like Hugging Face.\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "def convert_to_jsonl(csv_file_path, jsonl_file_path):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        with jsonlines.open(jsonl_file_path, mode='w') as writer:\n",
    "            for row in csv_reader:\n",
    "                writer.write(row)\n",
    "\n",
    "train_jsonl_output_path = 'train.jsonl'\n",
    "test_jsonl_output_path = 'test.jsonl'\n",
    "validation_jsonl_output_path = 'validation.jsonl'\n",
    "\n",
    "convert_to_jsonl(train_csv_output_path, train_jsonl_output_path)\n",
    "convert_to_jsonl(test_csv_output_path, test_jsonl_output_path)\n",
    "convert_to_jsonl(validation_csv_output_path, validation_jsonl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to import from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e36ff68e0244b8a92aaa61195e00444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c603c0710143d6a932edb87b5516fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb601cc79f24e92a18753b9dcdac7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e7dc124d0742579e2e5a8dbd276a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcf6e779bf4432393e2741936a96311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/394k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35556e41d2cc411c835948e4f9eec4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26ec83093c44fda4f7f9055d4f8e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793e6812e0d745de989b14fc22c5096d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a80d25aa7a64fc2bcfe3fcc57756cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try to load the uploaded dataset from huggingface BENBENBENb/McTest640COT\n",
    "mc160_train = load_dataset('BENBENBENb/McTest640COT', split='train')\n",
    "mc160_test = load_dataset('BENBENBENb/McTest640COT', split='test')\n",
    "mc160_validation = load_dataset('BENBENBENb/McTest640COT', split='validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
